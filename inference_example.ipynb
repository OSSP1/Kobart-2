{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c50c72a3",
      "metadata": {
        "id": "c50c72a3"
      },
      "source": [
        "# Inference and Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6caa0b92",
      "metadata": {
        "id": "6caa0b92"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BartForConditionalGeneration\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "from tqdm import tqdm\n",
        "from torchtext.data.metrics import bleu_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa07773",
      "metadata": {
        "id": "daa07773"
      },
      "source": [
        "## load tokenizer & model\n",
        "  - 표준어 -> 제주어 : s2d\n",
        "  - 제주어 -> 표준어 : d2s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0829a102",
      "metadata": {
        "id": "0829a102"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_kobart_tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed123a96",
      "metadata": {
        "id": "ed123a96"
      },
      "outputs": [],
      "source": [
        "model = BartForConditionalGeneration.from_pretrained('model_results/s2d/model/0522')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2656fe5",
      "metadata": {
        "id": "e2656fe5",
        "outputId": "9212d3ec-0284-401f-c615-6109d4f592c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> model set\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "model.to('cuda')\n",
        "print('>> model set')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3317049",
      "metadata": {
        "id": "b3317049"
      },
      "source": [
        "## load test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45fa408",
      "metadata": {
        "id": "f45fa408"
      },
      "outputs": [],
      "source": [
        "test_df=pd.read_csv('data/test_cleaned.tsv',sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33d9a84f",
      "metadata": {
        "id": "33d9a84f"
      },
      "outputs": [],
      "source": [
        "test_df.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18312ebc",
      "metadata": {
        "id": "18312ebc"
      },
      "source": [
        "### inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91703f9f",
      "metadata": {
        "id": "91703f9f"
      },
      "outputs": [],
      "source": [
        "idx = 1212\n",
        "sent = test_df['standard'][idx]\n",
        "print('input: ' , sent)\n",
        "print('gold: ' , test_df['dialect'][idx])\n",
        "\n",
        "inputs=tokenizer(sent,return_tensors='pt')\n",
        "\n",
        "outputs=model.generate(inputs['input_ids'].to('cuda'), eos_token_id=1, max_length=64, num_beams=5)\n",
        "print('generation: ', tokenizer.decode(outputs[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee04b8e9",
      "metadata": {
        "id": "ee04b8e9"
      },
      "source": [
        "### scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae0cb3b2",
      "metadata": {
        "id": "ae0cb3b2"
      },
      "outputs": [],
      "source": [
        "preds=[]\n",
        "for sent in tqdm(test_df['standard'][:100]):\n",
        "    inputs=tokenizer(sent,return_tensors='pt')\n",
        "    outputs=model.generate(inputs['input_ids'].to('cuda'), eos_token_id=1, max_length=64, num_beams=5)\n",
        "    preds.append(tokenizer.decode(outputs[0][1:-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d00ed9f0",
      "metadata": {
        "id": "d00ed9f0"
      },
      "outputs": [],
      "source": [
        "preds = [p.split() for p in preds]\n",
        "targets = [[d.split()] for d in test_df['dialect'][:100]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc9855d2",
      "metadata": {
        "id": "dc9855d2"
      },
      "outputs": [],
      "source": [
        "bleu_score(preds, targets)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}